<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Tolik Code</title>
    <link>http://tolikcode.github.io/post/</link>
    <description>Recent content in Posts on Tolik Code</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 15 Jan 2017 20:07:41 +0200</lastBuildDate>
    <atom:link href="http://tolikcode.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Any logs and Elasticsearch</title>
      <link>http://tolikcode.github.io/post/logstash/</link>
      <pubDate>Sun, 15 Jan 2017 20:07:41 +0200</pubDate>
      
      <guid>http://tolikcode.github.io/post/logstash/</guid>
      <description>

&lt;p&gt;Last time we looked at how and why you might want to write your application logs to Elasticsearch. But Elasticsearch is a great tool for many logging, monitoring and analytics cases. This blog post is an introduction to how Elasticsearch can help you analyze almost any data source, for example, your web server logs.&lt;/p&gt;

&lt;h2 id=&#34;logstash:5f55cedc7c54a8267431baeade267272&#34;&gt;Logstash&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://www.elastic.co/products/logstash&#34;&gt;Logstash&lt;/a&gt; is  a general purpose ETL (Extract-Transform-Load) tool, consisting of many inputs, filters and outputs. It&amp;rsquo;s a part of so-called Elastic Stack. Logstash helps you to put your data from different sources into Elasticsearch.&lt;/p&gt;

&lt;p&gt;There&amp;rsquo;s a good chance you are running you application in IIS if you are a .NET developer. There are &lt;a href=&#34;https://blogs.msdn.microsoft.com/friis/2014/02/06/how-to-analyse-iis-logs-using-logparser-logparser-studio/&#34;&gt;many tools&lt;/a&gt; to analyze IIS logs, but I haven&amp;rsquo;t seen anything as powerful as Elasticsearch. Analyzing your IIS logs with Elastic Stack might be especially interesting for you if you already use it for your other logs.&lt;/p&gt;

&lt;p&gt;I don&amp;rsquo;t want to repeat the general guidelines from many &lt;a href=&#34;https://improveandrepeat.com/2014/11/using-logstash-to-analyse-iis-log-files-with-kibana/&#34;&gt;existing&lt;/a&gt; &lt;a href=&#34;https://blog.sstorie.com/importing-iis-logs-into-elasticsearch-with-logstash/&#34;&gt;articles&lt;/a&gt; on how to use Logstash. The most important part there is Logstash config file. The most important part in the config file is the filter step.  Here&amp;rsquo;s my filter config:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## Ignore the comments that IIS will add to the start of the W3C logs
if [message] =~ &amp;quot;^#&amp;quot; {
  drop {}
}

grok {
  match =&amp;gt; [&amp;quot;message&amp;quot;, &amp;quot;%{TIMESTAMP_ISO8601:log_timestamp} %{NOTSPACE:s-site} %{WORD:cs-method} %{URIPATH:cs-uri-stem} %{NOTSPACE:cs-uri-query} %{NUMBER:s-port} %{NOTSPACE:cs-username} %{IPORHOST:c-ip} %{NOTSPACE:cs(User-Agent)} %{NOTSPACE:cs(Referer)} %{NUMBER:sc-status:int} %{NUMBER:sc-substatus:int} %{NUMBER:sc-win32-status:int} %{NUMBER:time-taken:int}&amp;quot;]
}

#Set the Event Timesteamp from the log
date {
  match =&amp;gt; [ &amp;quot;log_timestamp&amp;quot;, &amp;quot;YYYY-MM-dd HH:mm:ss&amp;quot; ]
  timezone =&amp;gt; &amp;quot;Etc/UTC&amp;quot;
} 

geoip {
  source =&amp;gt; &amp;quot;c-ip&amp;quot;
  target =&amp;gt; &amp;quot;geoip&amp;quot;
  add_tag =&amp;gt; [ &amp;quot;iis-geoip&amp;quot; ]
}
 
 
useragent {
  source=&amp;gt; &amp;quot;useragent&amp;quot;
  prefix=&amp;gt; &amp;quot;browser&amp;quot;
}
 
mutate {
 remove_field =&amp;gt; [ &amp;quot;log_timestamp&amp;quot;]
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;It should match your IIS log fields configuration. Mine worked great for the default IIS log fields configuration on Windows Server 2012. Use &lt;a href=&#34;https://grokdebug.herokuapp.com/&#34;&gt;Grok Debugger&lt;/a&gt; to troubleshoot it.&lt;/p&gt;

&lt;p&gt;A killer feature of Kibana for me was the ability to visualize the geography of requests to the server:&lt;/p&gt;

&lt;div class=&#34;standardBorder verticalMargins&#34; markdown=&#34;1&#34;&gt;
    &lt;img src=&#34;http://tolikcode.github.io/images/kibanaMap.png&#34;&gt;
&lt;/div&gt;

&lt;h2 id=&#34;notes:5f55cedc7c54a8267431baeade267272&#34;&gt;Notes:&lt;/h2&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Elasticsearch and Logstash are quite resource-consuming. That&amp;rsquo;s why it&amp;rsquo;s better to install them on a separate server and to use &lt;a href=&#34;https://www.elastic.co/products/beats/filebeat&#34;&gt;Filebeat&lt;/a&gt; to ship logs from your web server machine(s).&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Another interesting trick for real-time log analysis in high-load systems is to use ETW. In IIS Manager Logging section change Log Event Destination to ETW. This will create ETW events that can be captured by some windows service and written directly to ElasticSearch. This solution is a bit more complicated, but it allows to avoid writing logs to disk and their subsequent parsing.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;When I tried to visualize my IIS logs in Kibana I got the following error: &lt;code&gt;&amp;quot;Trying to query 1355 shards, which is over the limit of 1000. This limit exists because querying many shards at the same time can make the job of the coordinating node very CPU and/or memory intensive&amp;quot;&lt;/code&gt;. By default Logstash creates one Elasticsearch index for each day (IIS log file) and 5 shards per index. I resolved the issue by decreasing the number of shards per index. This is configured in &lt;a href=&#34;http://spuder.github.io/2015/elasticsearch-default-shards&#34;&gt;index template&lt;/a&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
</description>
    </item>
    
    <item>
      <title>Serilog and Elasticsearch</title>
      <link>http://tolikcode.github.io/post/elasticsearch/</link>
      <pubDate>Tue, 29 Nov 2016 20:55:18 +0200</pubDate>
      
      <guid>http://tolikcode.github.io/post/elasticsearch/</guid>
      <description>

&lt;p&gt;In my previous article about &lt;a href=&#34;http://tolikcode.github.io/post/uwpLogging/&#34;&gt;logging&lt;/a&gt; I didn&amp;rsquo;t really dig the semantic/structured logging. ETW was a bit complicated for my needs and the benefits of structural logging are not obvious with logging sinks like text file or SQL database. I gave it a shot with Serilog and Elasticsearch, and liked it a lot more.&lt;/p&gt;

&lt;h2 id=&#34;configuration:42d507d03b6380c8b6c5f61d637c346c&#34;&gt;Configuration&lt;/h2&gt;

&lt;p&gt;The first step is to install &lt;a href=&#34;https://www.elastic.co/products/elasticsearch&#34;&gt;Elasticsearch&lt;/a&gt;. Elasticsearch is an open source, distributed, RESTful search engine (that feels like a NoSQL database with powerful search and analytics capabilities). Its installation is pretty straightforward. The only thing I needed to do additionally was to install &lt;a href=&#34;http://www.oracle.com/technetwork/java/javase/downloads/server-jre8-downloads-2133154.html&#34;&gt;Server JRE&lt;/a&gt; and to configure a JAVA_HOME system variable.&lt;/p&gt;

&lt;p&gt;Then you add &lt;a href=&#34;https://serilog.net&#34;&gt;Serilog&lt;/a&gt; and a sink for Elasticsearch to your project. Serilog is a popular .NET logging library that supports structured logging. Getting them from NuGet:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;Install-Package Serilog
Install-Package Serilog.Sinks.ElasticSearch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Creating a logger instance:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var logger = new LoggerConfiguration()
                .WriteTo.Elasticsearch(new ElasticsearchSinkOptions(
                new Uri(&amp;quot;http://localhost:9200&amp;quot;))
                {
                    AutoRegisterTemplate = true
                }).CreateLogger();
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;For production projects I&amp;rsquo;d additionally create a wrapper around it and put it in some IoC container.&lt;/p&gt;

&lt;h2 id=&#34;writing-a-log:42d507d03b6380c8b6c5f61d637c346c&#34;&gt;Writing a log&lt;/h2&gt;

&lt;p&gt;After the configuration is finished writing a log entry to ElasticSearch boils down to just:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;logger.Information(&amp;quot;User {userId} made an order for {orderAmount}&amp;quot;, userId, orderAmount);
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Looks very similar to any other logging library, doesn&amp;rsquo;t it? However unlike most other libraries &lt;code&gt;userId&lt;/code&gt; and &lt;code&gt;orderAmount&lt;/code&gt; are not going to be formatted to string directly, but captured as separate meaningful values. They become fields by which you can index, search and sort. That&amp;rsquo;s the main benefit of structural logging.&lt;/p&gt;

&lt;h2 id=&#34;log-analysis:42d507d03b6380c8b6c5f61d637c346c&#34;&gt;Log analysis&lt;/h2&gt;

&lt;p&gt;Elasticsearch would be a lot less attractive without &lt;a href=&#34;https://www.elastic.co/products/kibana&#34;&gt;Kibana&lt;/a&gt;. Kibana is a powerful visualization platform on top of Elasticsearch. It allows to visualize and analyze your data with different graphs, charts, maps etc.&lt;/p&gt;

&lt;div class=&#34;standardBorder verticalMargins&#34; markdown=&#34;1&#34;&gt;
    &lt;img src=&#34;http://tolikcode.github.io/images/kibanaDashboard.png&#34;&gt;
&lt;/div&gt;

&lt;p&gt;There are situations when you have several logs and you want to aggregate data from them for analysis. For example in my current project I have at least three logs: Audit log for requests and responses (it&amp;rsquo;s a WebApi application), Sync log for requests to external SOAP services and a general application log. They are written to SQL databases. You have to write a &lt;code&gt;UNION&lt;/code&gt; query on several tables with different schemas to get a general picture of what&amp;rsquo;s going on in the application. To achieve the same in Kibana you just need to name your Elasticsearch indices with a pattern - some common prefix.&lt;/p&gt;

&lt;p&gt;Another helpful thing here is to use a &lt;code&gt;RequestId&lt;/code&gt; through out your logs. You can generate a unique &lt;code&gt;RequestId&lt;/code&gt; in some early stage of the request pipeline (HTTP module, Middleware, ActionFilter) and then include it in each log entry in different logs. This allows to see everything that have happened during a particular request - request body, corresponding response, exceptions and any other events.&lt;/p&gt;

&lt;p&gt;In conclusion you can have a great logging system with Serilog, Elasticsearch and Kibana. And all this goodness works in .NET Core also.
Too bad getting this to production servers through my management and client sysadmins is more difficult than actually developing this solution :)&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Yet another money manager</title>
      <link>http://tolikcode.github.io/post/moneyman/</link>
      <pubDate>Tue, 05 Apr 2016 17:49:51 +0300</pubDate>
      
      <guid>http://tolikcode.github.io/post/moneyman/</guid>
      <description>

&lt;p&gt;I got a little bored and decided to do some web development. I did several ASP.NET Web Forms projects back in university days and this is as far as my web development experience goes. That&amp;rsquo;s why I needed to go through a bunch of MVA courses and to read Jon Galloway&amp;rsquo;s &amp;ldquo;Professional ASP.NET MVC 5&amp;rdquo; book to update my skills. Just to test myself I wanted to develop a small project that would be at least of some use for me and give me enough drive to finish it.&lt;/p&gt;

&lt;p&gt;I&amp;rsquo;m trying to control how much money I spend and I need a solution to help me with this. There are plenty of expense managers already, but all of them never quite meet everyone&amp;rsquo;s exact dreams and wants as everyone handles it a little differently. They are also either not free, or with ads, or provide no cloud synchronization.&lt;/p&gt;

&lt;h2 id=&#34;project-description:7cced0d4ebc37f80338282bff66da165&#34;&gt;Project description&lt;/h2&gt;

&lt;p&gt;The goal of this project is to help you track your expenses and incomes. I want to keep it as simple as possible. I&amp;rsquo;d like to have a handy way to note my expenses anywhere I go with my phone and to have it all aggregated in a convenient form on my PC later.
The core of this solution is ASP.NET MVC application and a Web API for synchronization with an Android client. Android app is still in development.&lt;/p&gt;

&lt;p&gt;Web application screenshot is here just to get your attention (Disclaimer: I&amp;rsquo;m not a designer).&lt;/p&gt;

&lt;div class=&#34;standardBorder verticalMargins&#34; markdown=&#34;1&#34;&gt;
    &lt;img src=&#34;http://tolikcode.github.io/images/moneyManScreen.PNG&#34;&gt;
&lt;/div&gt;

&lt;h2 id=&#34;how-can-it-interest-you:7cced0d4ebc37f80338282bff66da165&#34;&gt;How can it interest you?&lt;/h2&gt;

&lt;p&gt;There are many similar projects. But none of them combine both of the following features:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Open source. You are free to fork it and modify it to meet your needs. You have a full control over your data. You can host your own copy anywhere you want.&lt;/li&gt;
&lt;li&gt;Both Android and web clients with synchronization.&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Some good alternatives:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;a href=&#34;http://www.moneymanagerex.org&#34;&gt;Money Manager EX&lt;/a&gt; - a free, open-source, cross-platform personal finance software.  Unfortunately it doesn&amp;rsquo;t have a web client and DropBox is required for synchronization.&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://web.andromoney.com&#34;&gt;AndroMoney&lt;/a&gt; - easy to use expense manager for Android, iOS and web.&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&#34;money-man-links:7cced0d4ebc37f80338282bff66da165&#34;&gt;Money Man links:&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/tolikcode/MoneyMan&#34;&gt;Sources on GitHub&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://moneyman.azurewebsites.net/&#34;&gt;Running application in Azure&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Taking the trash out with PowerShell</title>
      <link>http://tolikcode.github.io/post/recycleBinPowerShell/</link>
      <pubDate>Sun, 15 Nov 2015 11:12:12 +0200</pubDate>
      
      <guid>http://tolikcode.github.io/post/recycleBinPowerShell/</guid>
      <description>

&lt;p&gt;Many Windows users tend to store all of their old unnecessary files in the Recycle Bin. However, it just irritates me to know that files I almost definitely won&amp;rsquo;t ever need are still taking space up on my hard drive. Immediately deleting these files bypassing the Recycle Bin is also not an option here.&lt;/p&gt;

&lt;h2 id=&#34;goal:9f7a0d51badf47810d72f2123425000b&#34;&gt;Goal&lt;/h2&gt;

&lt;p&gt;Recycle Bin should be something like a safety net in case of mistakenly deleted files and pretend it doesn&amp;rsquo;t even exist otherwise. Windows automatically empties your Recycle Bin when it reaches certain size limit. In my opinion there should be a time limit additionally to the size limit in the Recycle Bin.
There are third party applications that might help you with it. But people like me who are irritated by three month old files in their Recycle Bins are probably not going to be very happy with an application cluttering their computers just for this simple task. Fortunately you can do it with PowerShell.&lt;/p&gt;

&lt;h2 id=&#34;solution:9f7a0d51badf47810d72f2123425000b&#34;&gt;Solution&lt;/h2&gt;

&lt;p&gt;After some googling I&amp;rsquo;ve found a detailed answer from &lt;code&gt;Indrek&lt;/code&gt; on &lt;a href=&#34;http://superuser.com/a/434673&#34;&gt;SuperUser&lt;/a&gt;. I liked the answer so much I decided to copy it here. It&amp;rsquo;s also a nice opportunity to learn a bit of PowerShell.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;ForEach ($Drive in Get-PSDrive -PSProvider FileSystem) {
    $Path = $Drive.Name + &#39;:\$Recycle.Bin&#39;
    Get-ChildItem $Path -Force -Recurse -ErrorAction SilentlyContinue |
    Where-Object { $_.LastWriteTime -lt (Get-Date).AddDays(-30) } |
    Remove-Item -Recurse
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can find a line-by-line explanation of this script in the original post from &lt;code&gt;Indrek&lt;/code&gt;. The script iterates over your disks, checks Recycle Bin folders and deletes all files that were put there more than some predefined period of time ago (in this case 30 days).&lt;/p&gt;

&lt;p&gt;Save this script as a text file with a &lt;code&gt;.ps1&lt;/code&gt; extension. You can then use Task Scheduler to run this at regular intervals. Open Task Scheduler and create a new task with the following parameters:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;Under the &amp;ldquo;General&amp;rdquo; tab, enter a name and check the &amp;ldquo;Run with highest privileges&amp;rdquo; option.&lt;/li&gt;
&lt;li&gt;Under the &amp;ldquo;Triggers&amp;rdquo; tab, add a new trigger and set the task to run daily.&lt;/li&gt;
&lt;li&gt;Under the &amp;ldquo;Actions&amp;rdquo; tab, add a new action:

&lt;ul&gt;
&lt;li&gt;set the &amp;ldquo;Program/script&amp;rdquo; field to &lt;code&gt;powershell&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;set the &amp;ldquo;Add arguments&amp;rdquo; field to &lt;code&gt;-NonInteractive -NoProfile -ExecutionPolicy RemoteSigned -File &amp;quot;C:\path\to\script.ps1&amp;quot;&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;I&amp;rsquo;ve been using this solution for several months already and it works like a charm.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Logging in Universal Windows applications</title>
      <link>http://tolikcode.github.io/post/uwpLogging/</link>
      <pubDate>Sat, 24 Oct 2015 23:23:55 +0300</pubDate>
      
      <guid>http://tolikcode.github.io/post/uwpLogging/</guid>
      <description>

&lt;p&gt;As a Windows Phone developer I always envied Android developers with their quite handy out of the box logging solution, namely LogCat. It allows both to output debug information in real time and to write it somewhere permanently.&lt;/p&gt;

&lt;p&gt;With Windows 10 being released I was hoping to have something similar to Android LogCat in Windows. Alas, there are a few changes to ETW Tracing and that&amp;rsquo;s all. If your have a Windows Phone / Window 8 development experience there is going to be nothing new for you.&lt;/p&gt;

&lt;h2 id=&#34;etw-tracing:2856d4dc02b2154b98472d85debbb153&#34;&gt;ETW Tracing&lt;/h2&gt;

&lt;p&gt;The Microsoft way for logging in UWP applications is via &lt;a href=&#34;https://msdn.microsoft.com/en-us/library/windows/desktop/aa363668&#34;&gt;Event Tracing for Windows&lt;/a&gt;. You can find a corresponding sample from Microsoft on &lt;a href=&#34;https://github.com/Microsoft/Windows-universal-samples/tree/master/Samples/Logging&#34;&gt;GitHub&lt;/a&gt;. This technology has been around both in desktop and mobile versions of Windows for quite some time already.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeGreen&#34;&gt;+ &lt;/span&gt; Out of the box. No need to reference any additional libraries.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeGreen&#34;&gt;+ &lt;/span&gt; Semantic logging. Your logs are going to have a consistent structure that makes it easier to analyze them.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeRed&#34;&gt;- &lt;/span&gt; Requires an effort to configure.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeRed&#34;&gt;- &lt;/span&gt; By default the result is going to be &lt;code&gt;*.etl&lt;/code&gt; files that have to be decoded.&lt;/p&gt;

&lt;h2 id=&#34;metrolog:2856d4dc02b2154b98472d85debbb153&#34;&gt;MetroLog&lt;/h2&gt;

&lt;p&gt;There are many different third party libraries for logging in Universal Windows applications. The most popular one is &lt;a href=&#34;https://www.nuget.org/packages/MetroLog/&#34;&gt;MetroLog&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeGreen&#34;&gt;+ &lt;/span&gt; Easy to configure.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeGreen&#34;&gt;+ &lt;/span&gt; Plain old text files. MetroLog can output to different targets, but it&amp;rsquo;s really easy to configure it to write everything into a &lt;code&gt;*.txt&lt;/code&gt; file.&lt;/p&gt;

&lt;p&gt;&lt;span class=&#34;largeRed&#34;&gt;- &lt;/span&gt; Additional reference in your application.&lt;/p&gt;

&lt;h2 id=&#34;retrieving-logs-from-a-windows-phone:2856d4dc02b2154b98472d85debbb153&#34;&gt;Retrieving logs from a Windows phone&lt;/h2&gt;

&lt;p&gt;Whether you&amp;rsquo;re doing ETW tracing or using a third party library (or your own custom solution) you are going to need to retrieve your logs from a device. You can upload them to some server or just prompt users to email them directly to you. In case you have a physical access to a test device
the easiest and most convenient way is to use &lt;a href=&#34;https://wptools.codeplex.com&#34;&gt;Windows Phone Power Tools&lt;/a&gt;. I&amp;rsquo;ve tested it with Windows 10 Mobile Insider Preview and it works great.&lt;/p&gt;

&lt;h2 id=&#34;application-insights:2856d4dc02b2154b98472d85debbb153&#34;&gt;Application Insights&lt;/h2&gt;

&lt;p&gt;In Visual Studio 2015 Microsoft has added &lt;a href=&#34;https://azure.microsoft.com/en-us/services/application-insights/&#34;&gt;Application Insights&lt;/a&gt; into Universal App project template. Application Insights is a comprehensive application monitoring solution available in Azure cloud. It allows to monitor the availability, performance, and usage metrics of different applications and services, and it might help you to solve the problems you wanted to solve with logging.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Hosting a Hugo generated site on GitHub</title>
      <link>http://tolikcode.github.io/post/hugoOnGitHub/</link>
      <pubDate>Sun, 04 Oct 2015 21:01:22 +0300</pubDate>
      
      <guid>http://tolikcode.github.io/post/hugoOnGitHub/</guid>
      <description>

&lt;p&gt;The reason I like Hugo so much is partly because of its great &lt;a href=&#34;http://gohugo.io/overview/introduction/&#34;&gt;documentation&lt;/a&gt;. Yet I do believe that  &lt;a href=&#34;http://gohugo.io/tutorials/github-pages-blog/&#34;&gt;Hosting on GitHub&lt;/a&gt; tutorial can be improved a little. It contains some redundant information on how to create a blog with Hugo and focuses on GitHub &lt;em&gt;Project&lt;/em&gt; Pages for the most part. It does provide you with steps on how to host a personal blog on GitHub &lt;em&gt;User&lt;/em&gt; Pages, but this solution requires separate repositories for your blog&amp;rsquo;s source and generated static result. And with &lt;code&gt;git subtree&lt;/code&gt; you can do it in one GitHub repo. It took me some time to configure everything especially that I knew little about &lt;code&gt;git subtree&lt;/code&gt;. So I&amp;rsquo;ve decided to write my own article on GitHub publishing.&lt;/p&gt;

&lt;h2 id=&#34;prerequisites:adf90425c55aea6c37dbfd72255f1e59&#34;&gt;Prerequisites&lt;/h2&gt;

&lt;p&gt;I assume that you are familiar with Git and have already generated a &lt;a href=&#34;https://gohugo.io/overview/quickstart/&#34;&gt;Hugo website&lt;/a&gt;.
You are going to have something like this in your website&amp;rsquo;s directory:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;archetypes
content
data
layouts
public
static
themes
config.toml
README.md
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;public&lt;/code&gt; folder contains your generated static website. I&amp;rsquo;ve also added &lt;code&gt;README.md&lt;/code&gt;.&lt;/p&gt;

&lt;h2 id=&#34;goal:adf90425c55aea6c37dbfd72255f1e59&#34;&gt;Goal&lt;/h2&gt;

&lt;p&gt;So you want to host your Hugo generated website on GitHub Pages. It&amp;rsquo;s natural to put your site&amp;rsquo;s sources in a GitHub repo too.
With &lt;a href=&#34;https://jekyllrb.com/&#34;&gt;Jekyll&lt;/a&gt; you can just put everything in your &lt;code&gt;master&lt;/code&gt; branch and GitHub would handle everything else for you.
In the case of Hugo we need to do some additional work as GitHub requires your static website to be in the root of the &lt;code&gt;master&lt;/code&gt; branch.&lt;/p&gt;

&lt;p&gt;The idea is to have the contents of &lt;code&gt;public&lt;/code&gt; folder on your &lt;code&gt;master&lt;/code&gt; branch, whereas other source files on some other orphan branch (e.g. &lt;code&gt;source&lt;/code&gt;). The &lt;code&gt;public&lt;/code&gt; folder on your &lt;code&gt;source&lt;/code&gt; branch is going to mirror the &lt;code&gt;master&lt;/code&gt; branch. This can be achieved with &lt;code&gt;git subtree&lt;/code&gt;. I encourage you to read more about &lt;code&gt;git subtree&lt;/code&gt;, however if you don&amp;rsquo;t feel like reading much today or just want to get results faster, here&amp;rsquo;s a tutorial for you.&lt;/p&gt;

&lt;h2 id=&#34;solution:adf90425c55aea6c37dbfd72255f1e59&#34;&gt;Solution&lt;/h2&gt;

&lt;p&gt;I usually use &lt;a href=&#34;https://www.sourcetreeapp.com/&#34;&gt;SourceTree&lt;/a&gt; for most of my Git related work. Unfortunately SourceTree doesn&amp;rsquo;t work very well with &lt;a href=&#34;https://jira.atlassian.com/browse/SRCTREEWIN-1643&#34;&gt;Git&lt;/a&gt; &lt;a href=&#34;https://jira.atlassian.com/browse/SRCTREEWIN-1819&#34;&gt;subtrees&lt;/a&gt;. Don&amp;rsquo;t worry anyway. There are just a few commands you need to type in your terminal.&lt;/p&gt;

&lt;p&gt;Initialize the &lt;code&gt;master&lt;/code&gt; branch:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;# Unstage all files
git rm -rf --cached .

git add README.md

git commit -m &amp;quot;Initial commit on master&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Commit everything to an orphan &lt;code&gt;source&lt;/code&gt; branch:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git checkout --orphan source

# Remove the public folder to make room for the master branch subtree
rm -rf public

git add .

git commit -m &amp;quot;Initial commit on source branch&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Push everything to GitHub:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git remote add origin https://github.com/tolikcode/tolikcode.github.io.

git push origin master

git push origin source
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This is the most crucial command in this article. Add the &lt;code&gt;master&lt;/code&gt; branch as a &lt;code&gt;public&lt;/code&gt; folder:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git subtree add --prefix=public https://github.com/tolikcode/tolikcode.github.io.git master --squash
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;workflow:adf90425c55aea6c37dbfd72255f1e59&#34;&gt;Workflow&lt;/h2&gt;

&lt;p&gt;That&amp;rsquo;s it! Your website is hosted on GitHub. Now your blogging workflow should be fairly simple. You just add new blogposts, edit templates, themes etc. Then you regenerate your website and commit everything to the &lt;code&gt;source&lt;/code&gt; branch:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;hugo -t ThemeName
git add -A
git commit -m &amp;quot;Updating site&amp;quot; &amp;amp;&amp;amp; git push origin source
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you have done everything correctly your Git commit history should look something like this:&lt;/p&gt;

&lt;div class=&#34;center verticalMargins&#34; markdown=&#34;1&#34;&gt;
    &lt;img src=&#34;http://tolikcode.github.io/images/HugoOnGithubHistory.png&#34;&gt;
&lt;/div&gt;

&lt;p&gt;When your changes are ready to see the world just publish them with &lt;code&gt;subtree push&lt;/code&gt; command to the &lt;code&gt;master&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-bash&#34;&gt;git subtree push --prefix=public https://github.com/tolikcode/tolikcode.github.io.git master
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now you can find your shiny new website at &lt;code&gt;http://yourusername.github.io/&lt;/code&gt;.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>